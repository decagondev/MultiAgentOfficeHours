{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install streamlit langchain langchain-core typing langchain_community langchain_openai langgraph"
      ],
      "metadata": {
        "id": "BAWqGUZZ_twS"
      },
      "id": "BAWqGUZZ_twS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "25fe95cd",
      "metadata": {
        "id": "25fe95cd"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import os\n",
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import create_agent_executor\n",
        "from langchain_core.pydantic_v1 import BaseModel\n",
        "from langchain.chains.openai_functions import create_structured_output_runnable\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import Annotated, Any, Dict, Optional, Sequence, TypedDict, List, Tuple\n",
        "import operator\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1089d1df",
      "metadata": {
        "id": "1089d1df"
      },
      "source": [
        "## Define Environment Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "eb096563",
      "metadata": {
        "id": "eb096563"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d2f01b08",
      "metadata": {
        "id": "d2f01b08"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0,\n",
        "                          max_tokens=1024,\n",
        "    model=\"gpt-4-1106-preview\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23d98a4f",
      "metadata": {
        "id": "23d98a4f"
      },
      "source": [
        "## Graph Node - Programmer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d692412",
      "metadata": {
        "id": "5d692412"
      },
      "source": [
        "#### Programmer Agent - Specialized in Writing Program based on Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7bebfac",
      "metadata": {
        "id": "a7bebfac"
      },
      "outputs": [],
      "source": [
        "class Code(BaseModel):\n",
        "    \"\"\"Plan to follow in future\"\"\"\n",
        "\n",
        "    code: str = Field(\n",
        "        description=\"Detailed optmized error-free Python code on the provided requirements\"\n",
        "    )\n",
        "\n",
        "\n",
        "from langchain.chains.openai_functions import create_structured_output_runnable\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "code_gen_prompt = ChatPromptTemplate.from_template(\n",
        "    '''**Role**: You are a expert software python programmer. You need to develop python code\n",
        "**Task**: As a programmer, you are required to complete the function. Use a Chain-of-Thought approach to break\n",
        "down the problem, create pseudocode, and then write the code in Python language. Ensure that your code is\n",
        "efficient, readable, and well-commented.\n",
        "\n",
        "**Instructions**:\n",
        "1. **Understand and Clarify**: Make sure you understand the task.\n",
        "2. **Algorithm/Method Selection**: Decide on the most efficient way.\n",
        "3. **Pseudocode Creation**: Write down the steps you will follow in pseudocode.\n",
        "4. **Code Generation**: Translate your pseudocode into executable Python code\n",
        "\n",
        "*REQURIEMENT*\n",
        "{requirement}'''\n",
        ")\n",
        "coder = create_structured_output_runnable(\n",
        "    Code, llm, code_gen_prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f4b87069",
      "metadata": {
        "id": "f4b87069"
      },
      "outputs": [],
      "source": [
        "code_ = coder.invoke({'requirement':'Generate fibbinacci series'})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ab5d77",
      "metadata": {
        "id": "95ab5d77"
      },
      "source": [
        "## Graph Node - Tester"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e7bfa42",
      "metadata": {
        "id": "1e7bfa42"
      },
      "source": [
        "#### Tester Agent - Generates input test cases and expected output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f3902cae",
      "metadata": {
        "id": "f3902cae"
      },
      "outputs": [],
      "source": [
        "class Test(BaseModel):\n",
        "    \"\"\"Plan to follow in future\"\"\"\n",
        "\n",
        "    Input: List[List] = Field(\n",
        "        description=\"Input for Test cases to evaluate the provided code\"\n",
        "    )\n",
        "    Output: List[List] = Field(\n",
        "        description=\"Expected Output for Test cases to evaluate the provided code\"\n",
        "    )\n",
        "\n",
        "\n",
        "from langchain.chains.openai_functions import create_structured_output_runnable\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "test_gen_prompt = ChatPromptTemplate.from_template(\n",
        "    '''**Role**: As a tester, your task is to create Basic and Simple test cases based on provided Requirement and Python Code.\n",
        "These test cases should encompass Basic, Edge scenarios to ensure the code's robustness, reliability, and scalability.\n",
        "**1. Basic Test Cases**:\n",
        "- **Objective**: Basic and Small scale test cases to validate basic functioning\n",
        "**2. Edge Test Cases**:\n",
        "- **Objective**: To evaluate the function's behavior under extreme or unusual conditions.\n",
        "**Instructions**:\n",
        "- Implement a comprehensive set of test cases based on requirements.\n",
        "- Pay special attention to edge cases as they often reveal hidden bugs.\n",
        "- Only Generate Basics and Edge cases which are small\n",
        "- Avoid generating Large scale and Medium scale test case. Focus only small, basic test-cases\n",
        "*REQURIEMENT*\n",
        "{requirement}\n",
        "**Code**\n",
        "{code}\n",
        "'''\n",
        ")\n",
        "tester_agent = create_structured_output_runnable(\n",
        "    Test, llm, test_gen_prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4794c86b",
      "metadata": {
        "id": "4794c86b"
      },
      "outputs": [],
      "source": [
        "print(code_.code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "087dcc13",
      "metadata": {
        "scrolled": false,
        "id": "087dcc13"
      },
      "outputs": [],
      "source": [
        "test_ = tester_agent.invoke({'requirement':'Generate fibbinacci series','code':code_.code})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3981798a",
      "metadata": {
        "id": "3981798a"
      },
      "outputs": [],
      "source": [
        "test_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6c9e3c6",
      "metadata": {
        "id": "c6c9e3c6"
      },
      "source": [
        "## Graph Node - Python Executor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89fd5bbf",
      "metadata": {
        "id": "89fd5bbf"
      },
      "source": [
        "#### Executor - Executes code in a Python environment on provided test cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "42b9fda3",
      "metadata": {
        "id": "42b9fda3"
      },
      "outputs": [],
      "source": [
        "class ExecutableCode(BaseModel):\n",
        "    \"\"\"Plan to follow in future\"\"\"\n",
        "\n",
        "    code: str = Field(\n",
        "        description=\"Detailed optmized error-free Python code with test cases assertion\"\n",
        "    )\n",
        "\n",
        "python_execution_gen = ChatPromptTemplate.from_template(\n",
        "    \"\"\"You have to add testing layer in the *Python Code* that can help to execute the code. You need to pass only Provided Input as argument and validate if the Given Expected Output is matched.\n",
        "*Instruction*:\n",
        "- Make sure to return the error if the assertion fails\n",
        "- Generate the code that can be execute\n",
        "Python Code to excecute:\n",
        "*Python Code*:{code}\n",
        "Input and Output For Code:\n",
        "*Input*:{input}\n",
        "*Expected Output*:{output}\"\"\"\n",
        ")\n",
        "execution = create_structured_output_runnable(\n",
        "    ExecutableCode, llm, python_execution_gen\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "65b58139",
      "metadata": {
        "id": "65b58139"
      },
      "outputs": [],
      "source": [
        "code_execute = execution.invoke({\"code\":code_.code,\"input\":test_.Input,'output':test_.Output})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f50e5c97",
      "metadata": {
        "id": "f50e5c97"
      },
      "outputs": [],
      "source": [
        "print(code_execute.code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9397a93c",
      "metadata": {
        "scrolled": true,
        "id": "9397a93c"
      },
      "outputs": [],
      "source": [
        "error = None\n",
        "try:\n",
        "    exec(code_execute.code)\n",
        "except Exception as e:\n",
        "    error = f'Exception : {e}'\n",
        "error"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73c2021c",
      "metadata": {
        "id": "73c2021c"
      },
      "source": [
        "## Graph Node -Debugger"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "451bb1c5",
      "metadata": {
        "id": "451bb1c5"
      },
      "source": [
        "#### Debugger - Debugs code using LLM knowledge and sends it back to the 'Executer' Agent in case of errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "a1fa1a5e",
      "metadata": {
        "id": "a1fa1a5e"
      },
      "outputs": [],
      "source": [
        "class RefineCode(BaseModel):\n",
        "\n",
        "    code: str = Field(\n",
        "        description=\"Optimized and Refined Python code to resolve the error\"\n",
        "    )\n",
        "\n",
        "\n",
        "python_refine_gen = ChatPromptTemplate.from_template(\n",
        "    \"\"\"You are expert in Python Debugging. You have to analysis Given Code and Error and generate code that handles the error\n",
        "    *Instructions*:\n",
        "    - Make sure to generate error free code\n",
        "    - Generated code is able to handle the error\n",
        "\n",
        "    *Code*: {code}\n",
        "    *Error*: {error}\n",
        "    \"\"\"\n",
        ")\n",
        "refine_code = create_structured_output_runnable(\n",
        "    RefineCode, llm, python_refine_gen\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0c5b5fd8",
      "metadata": {
        "id": "0c5b5fd8"
      },
      "outputs": [],
      "source": [
        "dummy_json = {\n",
        "    \"code\": code_execute.code,\n",
        "    \"error\": error\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6e7fdf63",
      "metadata": {
        "id": "6e7fdf63"
      },
      "outputs": [],
      "source": [
        "refine_code_ = refine_code.invoke(dummy_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a39a6514",
      "metadata": {
        "id": "a39a6514"
      },
      "outputs": [],
      "source": [
        "print(refine_code_.code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c44d93a",
      "metadata": {
        "id": "9c44d93a"
      },
      "outputs": [],
      "source": [
        "exec(refine_code_.code)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bda90aa",
      "metadata": {
        "id": "6bda90aa"
      },
      "source": [
        "## Graph Design"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2f6276e8",
      "metadata": {
        "id": "2f6276e8"
      },
      "outputs": [],
      "source": [
        "class AgentCoder(TypedDict):\n",
        "    requirement: str\n",
        "    code: str\n",
        "    tests: Dict[str, any]\n",
        "    errors: Optional[str]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cb6dff71",
      "metadata": {
        "id": "cb6dff71"
      },
      "outputs": [],
      "source": [
        "def programmer(state):\n",
        "    print(f'Entering in Programmer')\n",
        "    requirement = state['requirement']\n",
        "    code_ = coder.invoke({'requirement':requirement})\n",
        "    return {'code':code_.code}\n",
        "\n",
        "def debugger(state):\n",
        "    print(f'Entering in Debugger')\n",
        "    errors = state['errors']\n",
        "    code = state['code']\n",
        "    refine_code_ = refine_code.invoke({'code':code,'error':errors})\n",
        "    return {'code':refine_code_.code,'errors':None}\n",
        "\n",
        "def executer(state):\n",
        "    print(f'Entering in Executer')\n",
        "    tests = state['tests']\n",
        "    input_ = tests['input']\n",
        "    output_ = tests['output']\n",
        "    code = state['code']\n",
        "    executable_code = execution.invoke({\"code\":code,\"input\":input_,'output':output_})\n",
        "    #print(f\"Executable Code - {executable_code.code}\")\n",
        "    error = None\n",
        "    try:\n",
        "        exec(executable_code.code)\n",
        "        print(\"Code Execution Successful\")\n",
        "    except Exception as e:\n",
        "        print('Found Error While Running')\n",
        "        error = f\"Execution Error : {e}\"\n",
        "    return {'code':executable_code.code,'errors':error}\n",
        "\n",
        "def tester(state):\n",
        "    print(f'Entering in Tester')\n",
        "    requirement = state['requirement']\n",
        "    code = state['code']\n",
        "    tests = tester_agent.invoke({'requirement':requirement,'code':code})\n",
        "    #tester.invoke({'requirement':'Generate fibbinaco series','code':code_.code})\n",
        "    return {'tests':{'input':tests.Input,'output':tests.Output}}\n",
        "\n",
        "def decide_to_end(state):\n",
        "    print(f'Entering in Decide to End')\n",
        "    if state['errors']:\n",
        "        return 'debugger'\n",
        "    else:\n",
        "        return 'end'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "40b0b9f8",
      "metadata": {
        "id": "40b0b9f8"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph\n",
        "\n",
        "workflow = StateGraph(AgentCoder)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"programmer\", programmer)\n",
        "workflow.add_node(\"debugger\", debugger)\n",
        "workflow.add_node(\"executer\", executer)\n",
        "workflow.add_node(\"tester\", tester)\n",
        "#workflow.add_node('decide_to_end',decide_to_end)\n",
        "\n",
        "# Build graph\n",
        "workflow.set_entry_point(\"programmer\")\n",
        "workflow.add_edge(\"programmer\", \"tester\")\n",
        "workflow.add_edge(\"debugger\", \"executer\")\n",
        "workflow.add_edge(\"tester\", \"executer\")\n",
        "#workflow.add_edge(\"executer\", \"decide_to_end\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"executer\",\n",
        "    decide_to_end,\n",
        "    {\n",
        "        \"end\": END,\n",
        "        \"debugger\": \"debugger\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "eabce06d",
      "metadata": {
        "id": "eabce06d"
      },
      "outputs": [],
      "source": [
        "requirement = \"\"\"Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target. You may assume that each input would have exactly one solution, and you may not use the same element twice.You can return the answer in any order.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81417f7b",
      "metadata": {
        "scrolled": false,
        "id": "81417f7b"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "while requirement != \"end\":\n",
        "  requirement = input(\"Give me a code task and end to exit> \")\n",
        "  if requirement == \"end\":\n",
        "    break\n",
        "  config = {\"recursion_limit\": 50}\n",
        "  inputs = {\"requirement\": requirement}\n",
        "  running_dict = {}\n",
        "  async for event in app.astream(inputs, config=config):\n",
        "      for k, v in event.items():\n",
        "          running_dict[k] = v\n",
        "          if k != \"__end__\":\n",
        "              print(v)\n",
        "              print('----------'*20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58dade0f",
      "metadata": {
        "id": "58dade0f"
      },
      "outputs": [],
      "source": [
        "print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9b43f2e",
      "metadata": {
        "id": "d9b43f2e"
      },
      "outputs": [],
      "source": [
        "print(v['code'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ba4f3bf",
      "metadata": {
        "id": "7ba4f3bf"
      },
      "outputs": [],
      "source": [
        "running_dict"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}